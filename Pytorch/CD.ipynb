{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "image_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop1): Dropout2d(p=0.1, inplace=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop2): Dropout2d(p=0.15, inplace=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop3): Dropout2d(p=0.15, inplace=False)\n",
      "  (fc1): Linear(in_features=10368, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.drop1 = nn.Dropout2d(p=0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.drop2 = nn.Dropout2d(p=0.15)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.drop3 = nn.Dropout2d(p=0.15)\n",
    "        \n",
    "        x = torch.randn(image_size,image_size).view(-1,1,image_size,image_size)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 2)\n",
    "        \n",
    "    def convs(self,x):\n",
    "        x = self.drop1(self.pool1(F.relu(self.conv1(x))))\n",
    "        x = self.drop2(self.pool2(F.relu(self.conv2(x))))\n",
    "        x = self.drop3(self.pool3(F.relu(self.conv3(x))))\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = self.fc1(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 3, 100, 100]' is invalid for input of size 187095000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-37415540b3f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training_data_C.npy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 3, 100, 100]' is invalid for input of size 187095000"
     ]
    }
   ],
   "source": [
    "#data\n",
    "training_data = np.load(\"training_data_C.npy\", allow_pickle=True)\n",
    "\n",
    "x = torch.Tensor([i[0] for i in training_data]).view(-1, image_size, image_size)\n",
    "x = x/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "\n",
    "VAL_PCT = 0.1\n",
    "val_size = int(len(x)*VAL_PCT)\n",
    "\n",
    "train_x = x[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_x = x[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "np.save(\"train_x_C.npy\", train_x)\n",
    "np.save(\"train_y_C.npy\", train_y)\n",
    "\n",
    "np.save(\"test_x_C.npy\", test_x)\n",
    "np.save(\"test_y_C.npy\", test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not GPU train and test\n",
    "BATCH_SIZE = 100 #modify first\n",
    "EPOCHS = 1\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005, weight_decay=0.01)\n",
    "loss_f = nn.MSELoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_x), BATCH_SIZE)):\n",
    "        #print(i, i+BATCH_SIZE)\n",
    "        batch_x = train_x[i:i+BATCH_SIZE].view(-1,1,image_size,image_size)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "        \n",
    "        net.zero_grad() # /optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(batch_x)\n",
    "        loss = loss_f(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()  # Does the update\n",
    "        \n",
    "    print(f\"Epoch: {epoch} Loss: {loss}\")\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_x))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_x[i].view(-1,1,image_size,image_size))[0]\n",
    "        pre = torch.argmax(net_out)\n",
    "        if pre == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Acc: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting 1 GPU to the Neural Network\n"
     ]
    }
   ],
   "source": [
    "#Connect to gpu, Problem: used up dedicated GPU memory usage, soln: restart kernel\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    a = torch.cuda.device_count()\n",
    "    net = Net().to(device) #/ net.to(device)\n",
    "    print(f\"Connecting {a} GPU to the Neural Network\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GPU train and test\n",
    "def train(net):\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.00005, weight_decay=1e-9)\n",
    "    loss_f = nn.MSELoss()\n",
    "    BATCH_SIZE = 100\n",
    "    EPOCHS = 10\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_x), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "            #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "            batch_x = train_x[i:i+BATCH_SIZE].view(-1, 1, image_size, image_size)\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device) # !!!!!!!!\n",
    "            net.zero_grad()\n",
    "\n",
    "            optimizer.zero_grad()   # zero the gradient buffers\n",
    "            outputs = net(batch_x)\n",
    "            loss = loss_f(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()    # Does the update\n",
    "\n",
    "        print(f\"Epoch: {epoch} Loss: {loss}\")\n",
    "\n",
    "train(net)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in tqdm(range(0, len(test_x), BATCH_SIZE)):\n",
    "\n",
    "    batch_test_x = test_x[i:i+BATCH_SIZE].view(-1, 1, image_size, image_size).to(device)\n",
    "    batch_test_y = test_y[i:i+BATCH_SIZE].to(device)\n",
    "    batch_out = net(batch_test_x)\n",
    "\n",
    "    out_maxes = [torch.argmax(i) for i in batch_out]\n",
    "    target_maxes = [torch.argmax(i) for i in batch_test_y]\n",
    "    for i,j in zip(out_maxes, target_maxes):\n",
    "        if i == j:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-1595323500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:02<00:00,  3.58it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val_loss: 0.22505420446395874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:01<00:00,  3.64it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, val_loss: 0.2146010547876358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:01<00:00,  3.66it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, val_loss: 0.17956626415252686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:00<00:00,  3.69it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, val_loss: 0.17886018753051758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:59<00:00,  3.79it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, val_loss: 0.14978109300136566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:03<00:00,  3.55it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, val_loss: 0.16888019442558289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:01<00:00,  3.64it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, val_loss: 0.18764559924602509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:02<00:00,  3.57it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, val_loss: 0.14321857690811157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:01<00:00,  3.69it/s]\n",
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, val_loss: 0.14755116403102875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [01:02<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, val_loss: 0.09875667095184326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#GPU recorded train and test\n",
    "train_x = torch.Tensor(np.load(\"train_x.npy\", allow_pickle=True))\n",
    "train_y = torch.Tensor(np.load(\"train_y.npy\", allow_pickle=True))\n",
    "\n",
    "test_x = torch.Tensor(np.load(\"test_x.npy\", allow_pickle=True))\n",
    "test_y = torch.Tensor(np.load(\"test_y.npy\", allow_pickle=True))\n",
    "\n",
    "m_name = f\"model-{int(time.time())}\"\n",
    "\n",
    "net = Net().to(device) # !!!!!!!!\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-8)\n",
    "loss_f = nn.MSELoss()\n",
    "\n",
    "print(m_name)\n",
    "\n",
    "def fwd_pass(x, y, train=False):\n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "        \n",
    "    outputs = net(x)\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs,y)]\n",
    "    acc = matches.count(True)/len(matches)\n",
    "    loss = loss_f(outputs, y)\n",
    "    \n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return acc, loss\n",
    "\n",
    "def test(size=32):\n",
    "    random_start = np.random.randint(len(test_x)-size)\n",
    "    x, y = test_x[random_start:random_start+size], test_y[random_start:random_start+size]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_acc, val_loss = fwd_pass(x.view(-1,1,image_size,image_size).to(device), y.to(device))\n",
    "        \n",
    "    return val_acc, val_loss\n",
    "\n",
    "def train():\n",
    "    TEST_SIZE = 100\n",
    "    BATCH_SIZE = 100 #network big, batch size small #even number\n",
    "    EPOCHS = 10\n",
    "    \n",
    "    if os.path.exists('./model_result.log') != 1:\n",
    "        with open(\"model_result.log\", \"a\") as f:\n",
    "            f.write(\"name,times,acc,loss,val_acc,val_loss\\n\")\n",
    "            \n",
    "    with open(\"model_result.log\", \"a\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "            for i in tqdm(range(0, len(train_x), BATCH_SIZE)):\n",
    "                batch_x = train_x[i:i+BATCH_SIZE].view(-1, 1, image_size, image_size)\n",
    "                batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device) # !!!!!!!!\n",
    "                \n",
    "                acc, loss = fwd_pass(batch_x, batch_y, train=True)\n",
    "                if i % (BATCH_SIZE/2) == 0:\n",
    "                    val_acc, val_loss = test(size=TEST_SIZE)\n",
    "                    f.write(f\"{m_name},{round(time.time(),3)}, {round(float(acc),2)}, {round(float(loss),4)}, {round(float(val_acc),2)}, {round(float(val_loss),4)}\\n\")\n",
    "                    \n",
    "            print(f\"Epoch: {epoch}, val_loss: {val_loss}\")\n",
    "\n",
    "    with open(\"model_name.log\", \"a\") as f:\n",
    "        f.write(f\"{m_name}\\n\\n{net} + {optimizer}\\n\\n\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
